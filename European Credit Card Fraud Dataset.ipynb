{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2d32QzBQDnPg",
        "KlJj_wjyEKm4"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "VN-ptWDnA7kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas matplotlib scikit-learn imbalanced-learn seaborn tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "InxS39iMA7HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# Extract the relevant columns\n",
        "df = df[['Time', 'Amount', 'Class']]\n",
        "\n",
        "df = df.dropna(subset=['Class'])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "8VqSn37UD9-R",
        "outputId": "2967c129-d594-4957-dcae-5c872a429d6f"
      },
      "execution_count": null,
      "outputs": [
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform oversampling using RandomOverSampler\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "# Create a new DataFrame with the resampled data\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "df_resampled['Class'] = y_resampled\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = df_resampled.drop('Class', axis=1)\n",
        "y = df_resampled['Class']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "GGshxohNKTZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "MuE6mLp0BeCQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_Veom2bAxHk"
      },
      "outputs": [],
      "source": [
        "# Train the KNN model\n",
        "k = 5  # Example: using 5 neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "y_prob = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'True Positive Rate: {tpr:.4f}')\n",
        "print(f'False Positive Rate: {fpr:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NÃ¤ive Bayes"
      ],
      "metadata": {
        "id": "2d32QzBQDnPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the KNN model\n",
        "k = 5  # Example: using 5 neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "y_prob = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'True Positive Rate: {tpr:.4f}')\n",
        "print(f'False Positive Rate: {fpr:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IAZ0LAYUDmmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine"
      ],
      "metadata": {
        "id": "KlJj_wjyEKm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the SVM model\n",
        "svm_model = SVC(kernel='rbf', probability=True)  # You can specify different kernels as needed\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "y_prob = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'True Positive Rate: {tpr:.4f}')\n",
        "print(f'False Positive Rate: {fpr:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rHNFOMd5EPlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "aFcIbvuNEgQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of estimators as needed\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "y_prob = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'True Positive Rate: {tpr:.4f}')\n",
        "print(f'False Positive Rate: {fpr:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3hKyjvJvEj5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "hBsh2W1ZEo32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the ANN model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_prob = model.predict(X_test_scaled)\n",
        "y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'True Positive Rate: {tpr:.4f}')\n",
        "print(f'False Positive Rate: {fpr:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SCrvsz5gEq7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n"
      ],
      "metadata": {
        "id": "xVXu_suwBb2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Logistic Regression model\n",
        "log_reg_model = LogisticRegression()\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = log_reg_model.predict(X_test_scaled)\n",
        "y_prob = log_reg_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'ROC AUC Score: {roc_auc:.4f}')\n",
        "print(f'True Positive Rate: {tpr:.4f}')\n",
        "print(f'False Positive Rate: {fpr:.4f}')\n",
        "print(f'MCC: {mcc:.4f}')\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC Curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hsj3huuBBbaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
